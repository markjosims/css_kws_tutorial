{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d484088e",
   "metadata": {},
   "source": [
    "# Week 4: Keyword search using dynamic time warping\n",
    "This week we're going to apply KWS to some actual speech data. Even though last week we learned about WFSTs and how they can be applied to KWS, we're not going to talk about WFSTs or Markov models this week. Instead, we're going to introduce *Dynamic Time Warping* (DTW), a method for comparing to sequences of data that can be used for speech-to-speech KWS.\n",
    "\n",
    "\"Speech-to-speech\" means that instead of looking for a keyword by its *string*, we take the *audio* of an example keyword and compare the keyword audio to a sentence to determine if that sentence contains it. Since we're making comparisons between two different audio sequences, we need a metric that will describe the similarity of two sequences. That's where DTW comes into play.\n",
    "\n",
    "Before starting this week's coding exercise, I recommend watching [all four videos from Herman Kamper on DTW](https://www.youtube.com/playlist?list=PLmZlBIcArwhMJoGk5zpiRlkaHUqy5dLzL). Once you're done with that, we can dive into applying DTW to some audio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from librikws import *\n",
    "import numpy as np\n",
    "from tslearn.metrics import dtw_path, dtw, dtw_path_from_metric\n",
    "from scipy.spatial.distance import cdist, cosine\n",
    "from praatio import textgrid\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c21656",
   "metadata": {},
   "source": [
    "## Section 1: Comparing sequences with Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e12bd0",
   "metadata": {},
   "source": [
    "Hopefully by now you've watched the youtube videos, and you're familiar with DTW. Still, it's useful to have a demo to play with in Python. To do that, let's two simple sequences of 5 points, where the first sequence has a spike at the fourth point and the second sequence has a spike at the second point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b1a04-9359-4578-8dc5-58d6dd0f8746",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "seq_a = np.array([0,0,0,1,0])\n",
    "seq_b = np.array([0,1,0,0,0])\n",
    "ax.plot(seq_a, label='seq_a')\n",
    "ax.plot(seq_b, label='seq_b')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6cb258",
   "metadata": {},
   "source": [
    "I've included a simple implementation of the DTW algorithm so we can visualize what the matrix looks like for this sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38958f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtw_matrix(seq_a, seq_b, distance_funct = 'absolute_diff'):\n",
    "    if distance_funct == 'absolute_diff':\n",
    "        distance_funct = lambda a, b: np.abs(a-b)\n",
    "\n",
    "    # pad DTW matrix with an empty row\n",
    "    padded_len = seq_a.shape[0]+1\n",
    "    padded_width = seq_b.shape[0]+1\n",
    "    dtw_matrix = np.full((padded_len,padded_width), np.inf)\n",
    "    dtw_matrix[0,0]=0\n",
    "\n",
    "    for i, a_i in enumerate(seq_a, start=1):\n",
    "        for j, b_j in enumerate(seq_b, start=1):\n",
    "            current_distance = distance_funct(a_i, b_j)\n",
    "            \n",
    "            left = dtw_matrix[i,j-1]\n",
    "            bottom = dtw_matrix[i-1,j]\n",
    "            diag = dtw_matrix[i-1,j-1]\n",
    "\n",
    "            prev_distance = min(left, bottom, diag)\n",
    "\n",
    "            dtw_matrix[i,j] = current_distance + prev_distance\n",
    "    # trim padded\n",
    "    return dtw_matrix[1:,1:]\n",
    "\n",
    "def plot_distance_matrix(distance_matrix, ax):\n",
    "    ax.imshow(1-distance_matrix, origin='lower', cmap='Blues', aspect='auto')\n",
    "    ax.axis(\"off\")\n",
    "    # ax.autoscale(False)\n",
    "\n",
    "distance_matrix = get_dtw_matrix(seq_a, seq_b)\n",
    "fig, ax = plt.subplots()\n",
    "plot_distance_matrix(distance_matrix, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b80917",
   "metadata": {},
   "source": [
    "Let's plot the sequences alongside the matrix for best visibility and visualize the path through the DTW marix (code adapted from [tslearn documentation](https://tslearn.readthedocs.io/en/stable/auto_examples/metrics/plot_dtw.html#sphx-glr-auto-examples-metrics-plot-dtw-py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ac1eb-87d8-4118-9789-9787b00dbb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtw_axes() -> Tuple[plt.Axes, plt.Axes, plt.Axes]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "                Tuple[left_ax, center_ax, top_ax], pyplot axes\n",
    "                corresponding to top, center and left rectangles\n",
    "                where seq_a is visualized in top, seq_b in left\n",
    "                and the distance matrix and path in center.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    # definitions for the axes\n",
    "    left, bottom = 0.01, 0.1\n",
    "    left_width = top_height = 0.2\n",
    "    inner_left = left + left_width + 0.02\n",
    "    width = height = 0.65\n",
    "    bottom_of_top = bottom + height + 0.02\n",
    "    \n",
    "    # (left, bottom, width, height)\n",
    "    left_rectangle = [left, bottom, left_width, height]\n",
    "    center_rectangle = [inner_left, bottom, width, height]\n",
    "    top_rectangle = [inner_left, bottom_of_top, width, top_height]\n",
    "    \n",
    "    top_ax = plt.axes(top_rectangle)\n",
    "    center_ax = plt.axes(center_rectangle)\n",
    "    left_ax = plt.axes(left_rectangle)\n",
    "\n",
    "    return left_ax, center_ax, top_ax\n",
    "\n",
    "def plot_dtw_kws(seq_a, seq_b, distance_matrix=None, path=None):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        seq_a:              First sequence of numbers of vectors to compare\n",
    "        seq_b:              Second sequence of numbers of vectors to compare\n",
    "        distance_matrix:    Optional: pre-computed distance matrix (default\n",
    "                            behavior is to call `get_dtw_matrix(seq_a, seq_b)`)\n",
    "        path:               Optional: pre-computed path (default behavior is to\n",
    "                            call `tslearn.dtw_path(seq_a, seq_b)`)\n",
    "    \n",
    "    Plots two sequences along with similarity matrix and path.\n",
    "    \"\"\"\n",
    "    if distance_matrix is None:\n",
    "        distance_matrix = get_dtw_matrix(seq_a, seq_b)\n",
    "    if path is None:\n",
    "        path, _ = dtw_path(seq_a, seq_b)\n",
    "    \n",
    "    top, center, left = get_dtw_axes()\n",
    "    plot_distance_matrix(distance_matrix, center)\n",
    "    plot_path(path, center)\n",
    "    plot_left_seq(seq_b, left)\n",
    "    plot_top_seq(seq_a, top)\n",
    "    \n",
    "    dtw_distance = dtw(seq_a, seq_b)\n",
    "    left.set_title(f\"DTW score = {dtw_distance}\")\n",
    "\n",
    "    # plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "def plot_path(path, ax):\n",
    "    ax.plot(\n",
    "        [j for (i, j) in path],\n",
    "        [i for (i, j) in path],\n",
    "        \"r-\",\n",
    "        linewidth=3.\n",
    "    )\n",
    "\n",
    "def plot_left_seq(left_seq, left_ax):\n",
    "    left_ax.plot(np.arange(left_seq.shape[0]), left_seq, \"b-\", linewidth=3.)\n",
    "    left_ax.axis(\"off\")\n",
    "    left_ax.set_xlim((0, left_seq.shape[0] - 1))\n",
    "\n",
    "def plot_top_seq(top_seq, top_ax):\n",
    "    top_ax.plot(-top_seq, np.arange(top_seq.shape[0]), \"g-\", linewidth=3.)\n",
    "    top_ax.axis(\"off\")\n",
    "    top_ax.set_ylim((0, top_seq.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dtw_kws(seq_a, seq_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646838b",
   "metadata": {},
   "source": [
    "Since every point on this sequence pair can be mapped to a point that has exactly the same value, we get a DTW score of 0, indicating perfect alignment.\n",
    "\n",
    "Let's do the same with a sine and cosine wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeeb044-4ba2-4ac6-ad81-5581b565732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_seq = np.sin(np.arange(0, 10, step=0.1))\n",
    "cos_seq = np.cos(np.arange(0, 10, step=0.1))\n",
    "plot_dtw_kws(sin_seq, cos_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be7518",
   "metadata": {},
   "source": [
    "As we can see, since cosine and sine waves are basically the same function shifted by $\\pi/2$, there's a vertical section near the beginning and a horizontal section near the end that accounts for the misalingment, but for the rest of the DTW graph the path line is perfectly diagonal. In this case, we cannot perfectly align each point of one sequence to a point with 0 distance from it in the other sequence, so we get a nonzero DTW score.\n",
    "\n",
    "**EXERCISE 1:** Modify the code below to produce two pairs of sequences, the first pair where the DTW score is low (the sequences are very similar) and the second where the DTW score is high (the sequences are very different).\n",
    "\n",
    "For the first pair, try to make the sequences have a similar *shape* but different *alignment*, like `seq_a, seq_b` from above. Feel free to change the length of the arrays, to set values manually, or to use some function (e.g. `np.sin`, `np.tan`, `np.exp`, `np.factorial`, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f263422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "seq_a_lowscore = np.array([0,0,0,0,0,0])\n",
    "seq_b_lowscore = np.array([0,0,0,0,0,0])\n",
    "\n",
    "\n",
    "plot_dtw_kws(seq_a_lowscore, seq_b_lowscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "\n",
    "seq_a_highscore = np.array([0,0,0,0,0,0])\n",
    "seq_b_highscore = np.array([1,1,1,1,1,1])\n",
    "\n",
    "\n",
    "plot_dtw_kws(seq_a_highscore, seq_b_highscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b4e3a7",
   "metadata": {},
   "source": [
    "Let's do a quick demo of DTW on sequences of MFCCs using the toy dataset from last week. Below I've written code that will load in the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the ordered array of words\n",
    "words = np.load('data/words.npy')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the matrix of MFCCs for the audio\n",
    "mfcc_matrix = np.load('data/mfcc_matrix.npy')\n",
    "mfcc_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909c22d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the word id for each MFCC frame\n",
    "mfcc_word_ids = np.load('data/mfcc_word_ids.npy')\n",
    "mfcc_word_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6e898",
   "metadata": {},
   "source": [
    "**EXERCISE 2**: Write a function to get a matrix of all MFCCs for a given word (`np.argwhere(mfcc_word_ids=word_index)` will be helpful here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfccs_for_word(\n",
    "        word: str,\n",
    "        mfcc_word_ids: np.ndarray,\n",
    "        mfcc_matrix: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "    word_index = ...\n",
    "    # YOUR CODE HERE\n",
    "    return mfcc_matrix[:]\n",
    "\n",
    "lawn_mfccs = get_mfccs_for_word('lawn', mfcc_word_ids, mfcc_matrix)\n",
    "lawn_mfccs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3dee2",
   "metadata": {},
   "source": [
    "**EXERCISE 3:** Use the matrices computed above to:\n",
    "1. For each of the five words 'lawn, lean, knee, kneel, gnaw' predict what word will be *closest* and what word will be *furthest* from it.\n",
    "    - lawn:\n",
    "    - lean:\n",
    "    - knee:\n",
    "    - kneel:\n",
    "    - gnaw:\n",
    "2. Get the DTW score for each word. You can plot it with `plot_dtw` if you wish. To just get the DTW score call `dtw(seq_a, seq_b)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e220cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word_a in enumerate(words):\n",
    "    for word_b in words[i+1:]:\n",
    "        # YOUR CODE HERE: calculate the DTW score for word_a and word_b!\n",
    "        dtw_score = ...\n",
    "        print(f\"DTW score between {word_a} and {word_b} is {dtw_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b44a5e",
   "metadata": {},
   "source": [
    "Now that we've got some practice with MFCCs and in using them in DTW, we're going to start looking at some real KWS data. We'll be working with the [LibriSpeech](https://ieeexplore.ieee.org/document/7178964) and [LibriPhrase](https://arxiv.org/abs/2206.15400) datasets. LibriSpeech is an ASR dataset made from public domain audiobooks, and LibriPhrase is a KWS dataset where keywords were sampled from sentences in LibriSpeech. I've saved these datasets onto Witchking and provided some helper functions defined in `librikws.py` to load data from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf0b2c-b88a-4762-941d-6e915b2704a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = get_unique_keywords()\n",
    "print(f\"{len(keywords)} keywords in dataset\")\n",
    "keywords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eedd9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword, sentence = get_random_keyword_sentence_pair(keywords[42])\n",
    "keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039b126-b2c5-4c39-9a5c-49817ee4cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c615b8",
   "metadata": {},
   "source": [
    "Let's write a function to get MFCCs + the first and second derivatives for a given audio. We'll use this as feature extraction for doing KWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_w_deltas(audio: Union[str, np.ndarray], samplerate: Optional[int]=None) -> np.ndarray:\n",
    "    if type(audio) is str:\n",
    "        audio, samplerate = librosa.load(audio)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=samplerate, n_mfcc=13)\n",
    "    d1 = librosa.feature.delta(mfcc, order=1)\n",
    "    d2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "    feature = np.concat([mfcc, d1, d2], axis=0)\n",
    "    return feature\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.imshow(mfcc_w_deltas(get_librispeech_path(sentence['file'])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0572e",
   "metadata": {},
   "source": [
    "In order to visualize DTW between a keyword and a sentence, let's write another function to plot a sentence and keyword similar to the style used in `plot_dtw` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentence(\n",
    "        row: pd.Series,\n",
    "        tier: str='words',\n",
    "        stop_tokens: List[str] = ['sp', 'sil'],\n",
    "        ax: Optional[plt.Axes] = None,\n",
    "        audio_type: Literal['wav', 'mfcc']='wav'\n",
    "    ):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    audio_path = get_librispeech_path(row['file'])\n",
    "    wav, samplerate = librosa.load(audio_path)\n",
    "    textgrid_df = get_librispeech_textgrid(row['file'])\n",
    "\n",
    "    mfcc = mfcc_w_deltas(wav, samplerate)\n",
    "    if audio_type == 'mfcc':\n",
    "        text_y=30\n",
    "        ax.imshow(mfcc)\n",
    "        audio = mfcc\n",
    "    else:\n",
    "        audio = wav\n",
    "        ax.plot(audio)\n",
    "        text_y=-0.5\n",
    "        ax.set_ylim((-1,1))\n",
    "        \n",
    "    max_time = textgrid_df['end'].max()\n",
    "    max_X = audio.shape[-1]\n",
    "    ax.set_xlim(0, max_X)\n",
    "\n",
    "\n",
    "    midpoint=(textgrid_df['start']+textgrid_df['end'])/2\n",
    "    midpoint_relative = midpoint/max_time\n",
    "    midpoint_X = midpoint_relative*max_X\n",
    "    textgrid_df['midpoint_X']=midpoint_X\n",
    "\n",
    "    plot_word = lambda row: ax.text(\n",
    "        x = row['midpoint_X'],\n",
    "        y=text_y,\n",
    "        s = row['value'],\n",
    "        rotation=90,\n",
    "        fontsize=8,\n",
    "    )\n",
    "    tier_mask = textgrid_df['tier']==tier\n",
    "    stoptoken_mask = textgrid_df['value'].isin(stop_tokens)\n",
    "    textgrid_df[tier_mask&~stoptoken_mask].apply(plot_word, axis=1)\n",
    "\n",
    "\n",
    "    return mfcc.T\n",
    "\n",
    "plot_sentence(sentence)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e0b68",
   "metadata": {},
   "source": [
    "The `audio_type` arg let's us choose between visualizing the waveform or MFCCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbbd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentence(sentence, audio_type='mfcc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbbd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keyword(\n",
    "        row: pd.Series,\n",
    "        ax: Optional[plt.Axes] = None,\n",
    "        audio_type: Literal['wav', 'mfcc']='wav',\n",
    "):\n",
    "    audio_path = get_libriphrase_audio_path(row['file'])\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    mfcc = mfcc_w_deltas(audio_path)\n",
    "    if audio_type == 'mfcc':\n",
    "        ax.imshow(mfcc.T)\n",
    "        text_x=30\n",
    "        max_y=mfcc.shape[-1]\n",
    "\n",
    "    else:\n",
    "        wav, _ = librosa.load(audio_path)\n",
    "        time = np.arange(wav.shape[-1])\n",
    "        ax.plot(wav, time)\n",
    "        ax.set_xlim((-1,1))\n",
    "        text_x=-0.5\n",
    "        max_y=wav.shape[-1]\n",
    "\n",
    "    text_y = max_y/2\n",
    "\n",
    "    ax.text(\n",
    "        y=text_y,\n",
    "        x=text_x,\n",
    "        s = row['keyword'],\n",
    "        rotation=90,\n",
    "        fontsize=20,\n",
    "        va='center',\n",
    "        ha='center'\n",
    "    )\n",
    "\n",
    "\n",
    "    ax.set_ylim(0, max_y)\n",
    "\n",
    "    return mfcc.T\n",
    "plot_keyword(keyword)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c6bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_keyword(keyword, audio_type='mfcc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d0d49",
   "metadata": {},
   "source": [
    "Let's use these methods to visualize DTW between the MFCCs of the keyword and keyphrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dtw_mfccs(keyword, sentence):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        keyword:            pandas.Series containing data for keyword\n",
    "        sentence:           pandas.Series containing data for sentence\n",
    "        distance_matrix:    Optional: pre-computed distance matrix (default\n",
    "                            behavior is to call `get_dtw_matrix(seq_a, seq_b)`)\n",
    "        path:               Optional: pre-computed path (default behavior is to\n",
    "                            call `tslearn.dtw_path(seq_a, seq_b)`)\n",
    "    \n",
    "    Plots two sequences along with similarity matrix and path.\n",
    "    \"\"\"\n",
    "    left, center, top = get_dtw_axes()\n",
    "\n",
    "    keyword_mfcc=plot_keyword(keyword, ax=left)\n",
    "    sentence_mfcc=plot_sentence(sentence, ax=top)\n",
    "    # dtw_matrix=dtw_matrix = get_dtw_matrix(\n",
    "    #     keyword_mfcc,\n",
    "    #     sentence_mfcc,\n",
    "    #     distance_funct=cosine,\n",
    "    # )\n",
    "    distance_matrix = cdist(keyword_mfcc, sentence_mfcc)\n",
    "    path, _ = dtw_path(keyword_mfcc, sentence_mfcc)\n",
    "    plot_distance_matrix(distance_matrix, center)\n",
    "    plot_path(path, center)\n",
    "\n",
    "    dtw_distance = dtw(keyword_mfcc, sentence_mfcc) / sentence_mfcc.shape[0]\n",
    "    top.set_title(f\"DTW score = {dtw_distance}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_dtw_mfccs(keyword, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d25778",
   "metadata": {},
   "source": [
    "**EXERCISE 4:** Where the DTW path is more vertical, we are \"traversing\" along the keyword, as opposed to horizontal lines where we are traversing along the sentence but not along the keyword. Since the keyword is contained within the sentence, we should expect most of the vertical movement to occur at the keyword's location in the audio. Is this actually the case? In the markdown cell below, note the words in the sentence where you see vertical movement along the DTW path, and whether this is in line with what you expected.\n",
    "\n",
    "Note: The keyword here is set to 'I asked', but the sentence was randomly generated. If the sentence is too long and the words on top are too crowded, try running the cells above again until a shorter sentence is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e7550",
   "metadata": {},
   "source": [
    "YOUR ANWER HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46e0816",
   "metadata": {},
   "source": [
    "Now, it's not really ideal to compare an *entire* sentence of MFCCs to the keyphrase using DTW. A better strategy is to divide the sentence into a series of windows then compare each window to the keyword. Hopefully, the window with the minimum score will match the keyword (I've indicated the minium DTW score with a vertical red line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sliding_dtw(keyword, sentence):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        keyword:            pandas.Series containing data for keyword\n",
    "        sentence:           pandas.Series containing data for sentence\n",
    "        distance_matrix:    Optional: pre-computed distance matrix (default\n",
    "                            behavior is to call `get_dtw_matrix(seq_a, seq_b)`)\n",
    "        path:               Optional: pre-computed path (default behavior is to\n",
    "                            call `tslearn.dtw_path(seq_a, seq_b)`)\n",
    "    \n",
    "    Plots two sequences along with similarity matrix and path.\n",
    "    \"\"\"\n",
    "    left, center, top = get_dtw_axes()\n",
    "\n",
    "    keyword_mfcc=plot_keyword(keyword, ax=left)\n",
    "    sentence_mfcc=plot_sentence(sentence, ax=top)\n",
    "\n",
    "    dtw_scores = get_windowed_dtw(keyword_mfcc, sentence_mfcc)\n",
    "    min_idx = np.argmin(dtw_scores)\n",
    "    plot_distance_matrix(dtw_scores, center)\n",
    "    center.vlines(min_idx, -0.5, 0.5, 'red')\n",
    "\n",
    "    top.set_title(f\"Min DTW score = {dtw_scores.min()}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def get_windowed_dtw(keyword_mfcc, sentence_mfcc):\n",
    "    window_len = min(int(keyword_mfcc.shape[0]*1.5), sentence_mfcc.shape[0])\n",
    "    window_shape = (window_len, keyword_mfcc.shape[1])\n",
    "    sentence_windows = np.lib.stride_tricks.sliding_window_view(\n",
    "        sentence_mfcc,\n",
    "        window_shape,\n",
    "    ).squeeze()\n",
    "    dtw_scores = np.array([dtw(keyword_mfcc, window) for window in sentence_windows])\n",
    "    dtw_scores = dtw_scores[np.newaxis,:]\n",
    "    dtw_scores/=keyword_mfcc.shape[0]\n",
    "    return dtw_scores\n",
    "\n",
    "plot_sliding_dtw(keyword, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a722aa",
   "metadata": {},
   "source": [
    "Let's put this to the test with a small dataset. I've saved a csv file with a list of 10 keywords where each keywords is paired with 10 positive sentences (that contain the keyword) and 20 negative (that don't contain the keyword). The imbalance here is intentional: overall, we should expect to come across more instances of negative sentences than positive for any given keyword when applying KWS to novel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_df = get_samespeaker_kws_df()\n",
    "kws_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e253f29",
   "metadata": {},
   "source": [
    "Let's add a column containing the DTW score for each row, and then z-score it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d986aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtw_prob(row):\n",
    "    keyword_mfcc = mfcc_w_deltas(get_libriphrase_audio_path(row['keyword_file']))\n",
    "    sentence_mfcc = mfcc_w_deltas(get_librispeech_path(row['sentence_file']))\n",
    "\n",
    "    return get_windowed_dtw(keyword_mfcc, sentence_mfcc).min()\n",
    "\n",
    "kws_df['dtw_score']=kws_df.progress_apply(get_dtw_prob, axis=1)\n",
    "kws_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b745396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score dtw scores\n",
    "kws_df['dtw_score_norm'] = (kws_df['dtw_score']-kws_df['dtw_score'].mean())\\\n",
    "    / kws_df['dtw_score'].std()\n",
    "# apply sigmoid so scores are valued between 0 and 1\n",
    "kws_df['dtw_score_norm']= kws_df['dtw_score_norm'].apply(lambda x: 1/(1+np.exp(-x)))\n",
    "kws_df['dtw_score_norm'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8256031",
   "metadata": {},
   "source": [
    "Hopefully, a keyword-positive sentence pair will have a low DTW score and a keyword-negative sentence pair will have a high DTW score. Let's look at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = kws_df['keyword'].isin([\"commander\", \"japanese\"])\n",
    "sns.scatterplot(kws_df[:], y='label', x='dtw_score_norm', hue='keyword')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bce74a8",
   "metadata": {},
   "source": [
    "Here's an [article](https://www.geeksforgeeks.org/machine-learning/auc-roc-curve/) and a [video with cringy intro song](https://www.youtube.com/watch?v=4jRBRDbJemM) on ROC/AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefffcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = kws_df['label']\n",
    "# Y_hat is NEGATIVE dtw_score_norm\n",
    "# because greater DTW score = more distance\n",
    "# i.e. LESS similarity\n",
    "Y_hat = -kws_df['dtw_score_norm']\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y, Y_hat)\n",
    "auc = roc_auc_score(Y, Y_hat)\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier') # Diagonal line for random classifier\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9855c1",
   "metadata": {},
   "source": [
    "**EXERCISE 5:** Inspect the ROC curve and AUC value for each keyword individually and note which words have particularly low or high values. Remember that a low AUC means the word is harder to classify and a higher AUC means the word is easier to classify. Do you notice any trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29680f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_targets = kws_df['keyword'].unique()\n",
    "kws_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95336d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_keyword = kws_targets[0]\n",
    "mask = kws_df['keyword']==target_keyword\n",
    "\n",
    "Y = kws_df[mask]['label']\n",
    "Y_hat = -kws_df[mask]['dtw_score_norm']\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y, Y_hat)\n",
    "auc = roc_auc_score(Y, Y_hat)\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier') # Diagonal line for random classifier\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC Curve for keyword \"{target_keyword}\"')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09bf202",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76a808",
   "metadata": {},
   "source": [
    "**EXERCISE 6**: Let's try to improve our AUC score from 0.65! We can do this by tinkering with the features and with the way DTW is scored. Let's start with the features. So we've been using `MFCCs` with 13 coefficients. Let's try modifying this. Here are a few ideas:\n",
    "1. Change the number of coefficients `n_mfcc`. What happens to AUC when we add more coefficients? When we use less?\n",
    "2. Add *energy* to our feature vector. This can be done using `librosa.feature.rms`. You can concatenate energy to the MFCCs like this:\n",
    "\n",
    "```python\n",
    "energy = librosa.feature.rms(y=audio)\n",
    "feature = np.concat([mfcc, d1, d2, energy])\n",
    "```\n",
    "3. Add `d1_energy` and `d2_energy` (the first and second derivatives of energy) to our feature. Just repeat the steps for getting `d1` and `d2` of the MFCCs and concatenate to the feature.\n",
    "4. Why stop there? There are multiple audio features to play around with among the [Librosa features](https://librosa.org/doc/0.11.0/feature.html). I'd focus on spectral features, e.g. `librosa.feature.melspectrogram` or `librosa.feature.spectral_bandwidth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54763db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_alt(audio: Union[str, np.ndarray], samplerate: Optional[int]=None) -> np.ndarray:\n",
    "    if type(audio) is str:\n",
    "        audio, samplerate = librosa.load(audio)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=samplerate, n_mfcc=13)\n",
    "    d1 = librosa.feature.delta(mfcc, order=1)\n",
    "    d2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "    feature = np.concatenate([mfcc, d1, d2], axis=0)\n",
    "    return feature\n",
    "\n",
    "mfcc_alt(get_libriphrase_audio_path(kws_df.iloc[0]['keyword_file'])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd2578",
   "metadata": {},
   "source": [
    "As hinted above, we can modify how DTW is calculated as well. We can do this by changing the distance function used to compute distance between feature vectors. See the [scipy documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html) for more information on different distance metrics. You can change what distance metric `tslearn` uses by simply changing the `dtw_metric` variable in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windowed_dtw_alt(keyword_mfcc, sentence_mfcc):\n",
    "    window_len = min(int(keyword_mfcc.shape[0]*1.5), sentence_mfcc.shape[0])\n",
    "    window_shape = (window_len, keyword_mfcc.shape[1])\n",
    "    sentence_windows = np.lib.stride_tricks.sliding_window_view(\n",
    "        sentence_mfcc,\n",
    "        window_shape,\n",
    "    ).squeeze()\n",
    "\n",
    "    dtw_metric = 'euclidean' # MODIFY THIS LINE TO CHANGE THE METRIC\n",
    "\n",
    "    dtw_scores = np.array([dtw_path_from_metric(keyword_mfcc, window, metric=dtw_metric)[1] for window in sentence_windows])\n",
    "    dtw_scores = dtw_scores[np.newaxis,:]\n",
    "    dtw_scores/=keyword_mfcc.shape[0]\n",
    "    return dtw_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dtw_prob_alt(row):\n",
    "    keyword_mfcc = mfcc_alt(get_libriphrase_audio_path(row['keyword_file']))\n",
    "    sentence_mfcc = mfcc_alt(get_librispeech_path(row['sentence_file']))\n",
    "\n",
    "    return get_windowed_dtw_alt(keyword_mfcc, sentence_mfcc).min()\n",
    "\n",
    "kws_df['dtw_score_alt']=kws_df.progress_apply(get_dtw_prob_alt, axis=1)\n",
    "\n",
    "# z-score dtw scores\n",
    "kws_df['dtw_score_alt'] = (kws_df['dtw_score_alt']-kws_df['dtw_score_alt'].mean())\\\n",
    "    / kws_df['dtw_score_alt'].std()\n",
    "# apply sigmoid so scores are valued between 0 and 1\n",
    "kws_df['dtw_score_alt']= kws_df['dtw_score_alt'].apply(lambda x: 1/(1+np.exp(-x)))\n",
    "\n",
    "Y = kws_df['label']\n",
    "Y_hat = -kws_df['dtw_score_alt']\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y, Y_hat)\n",
    "auc = roc_auc_score(Y, Y_hat)\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier') # Diagonal line for random classifier\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f6a96",
   "metadata": {},
   "source": [
    "**YOUR ANSSER HERE:** In this cell, write down what changes you made to the feature generation and scoring metric and how that effected the AUC score.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
