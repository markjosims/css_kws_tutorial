{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f000494b",
   "metadata": {},
   "source": [
    "# ASR Tutorial Week 1: FSTs and language as graphs\n",
    "This week our goal is to understand and get some practice with representing language as a graph. We'll be using the `pynini` library to create and interact with Finite State Transducers (FSTs), a graph model frequently used for natural language.\n",
    "\n",
    "In this exercise, we'll practice using FSTs to map between words and phonemes. For ease of typing phonemes are represented using [Arpabet](https://en.wikipedia.org/wiki/ARPABET) rather than IPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynini\n",
    "import graphviz\n",
    "from typing import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5951aa70",
   "metadata": {},
   "source": [
    "## Section 1: Finite State Acceptors\n",
    "First let's get some basics on how FSTs work. First we'll discuss a special type of FST, a Finite State *Acceptor* (FSA). FSAs are a graph over a certain *language*, where a path on the graph corresponds to a \"word\" in the given language. Each *arc* on the graph corresponds to a given letter on the language's alphabet.\n",
    "\n",
    "For example, let's make a graph over the single word \"cat\".\n",
    "\n",
    "To do this we first need to create a `SymbolTable`. Since the FST stores each letter as an integer, we need to tell the FST how those integers are mapped to letters in order to visualize the FST with language instead of numbers. To start we'll just map letters to their ASCII code value. We use the `chr` function to convert and integer to it's ASCII character and the `ord` function to convert a character to its ASCII code value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc716e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ascii_table = pynini.SymbolTable()\n",
    "ascii_table.add_symbol('<eps>')\n",
    "for i in range(1, 123):\n",
    "    ascii_table.add_symbol(chr(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e75b90",
   "metadata": {},
   "source": [
    "Let's also write a function to visualize our FSTs (if you put an FST as the last line of code in a cell, it should render automatically, but I find that sometimes the rendering bugs out and messes up the symbols for the FST, whereas this function should be more reliable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbe4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fst(f):\n",
    "    tmp_path = 'tmp.dot'\n",
    "    f.draw(tmp_path, portrait=True)\n",
    "    with open(tmp_path) as file:\n",
    "        return graphviz.Source(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ea2ca",
   "metadata": {},
   "source": [
    "Now we can create the FSA (note that, since FSA's are a type of FST, we call `pynini.Fst()` to construct it). To make use of our symbol table, we call `Fst.set_input/output_symbols(ascii_table)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4955d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pynini.Fst()\n",
    "f.set_input_symbols(ascii_table)\n",
    "f.set_output_symbols(ascii_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18446b32",
   "metadata": {},
   "source": [
    "We then set about populating the graph. Each node in an FST is called a `state`. We start by adding an initial state. All paths through the graph of our FST will start from this state.\n",
    "\n",
    "Each state has an integer index. Whenever we call `f.add_state()` it returns the index of the state added. As you can see in the code snippet below, the first state added has index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51647fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = f.add_state()\n",
    "f.set_start(initial_state)\n",
    "print(initial_state)\n",
    "print_fst(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302b954",
   "metadata": {},
   "source": [
    "States are connected via arcs. In an FSA, an arc \"consumes\" a letter on the alphabet. If a word is in an FSA's language, then we spell out the word by \"consuming\" each letter in it as we traverse the arcs of the FSA. Let's illustrate this by adding an arc for 'c' going out of the initial state.\n",
    "\n",
    "We define an arc using `pynini.Arc` which takes the arguments `(input_label, output_label, weight, next_state)`. Don't worry about input vs. output labels right now, we'll explain the purpose of those later. For now, know that for an FSA the input and output labels for any arc are always the same. Likewise, we're ignoring `weight` for now, and so we're setting it to `None`. Since we're drawing an arc to the second state, we set `second_state` as the value for `next_state`.\n",
    "\n",
    "To add the arc to the graph, we use the `Fst.add_arc()` function which takes the arguments `(first_state, arc)`. Since we're drawing an arc from the initial state we pass `initial_state` to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_state = f.add_state()\n",
    "first_letter = 'c'\n",
    "first_letter_code = ord(first_letter)\n",
    "nullweight = None\n",
    "arc_to_second_state = pynini.Arc(first_letter_code, first_letter_code, nullweight, second_state)\n",
    "f.add_arc(initial_state, arc_to_second_state)\n",
    "print_fst(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb58590",
   "metadata": {},
   "source": [
    "Now let's make the rest of our word 'cat.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_state = f.add_state()\n",
    "second_letter = 'a'\n",
    "second_letter_code = ord(second_letter)\n",
    "arc_to_third_state = pynini.Arc(second_letter_code, second_letter_code, nullweight, third_state)\n",
    "f.add_arc(second_state, arc_to_third_state)\n",
    "\n",
    "fourth_state = f.add_state()\n",
    "third_letter = 't'\n",
    "third_letter_code = ord(third_letter)\n",
    "arc_to_fourth_state = pynini.Arc(third_letter_code, third_letter_code, nullweight, fourth_state)\n",
    "f.add_arc(third_state, arc_to_fourth_state)\n",
    "\n",
    "print_fst(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cdc7a0",
   "metadata": {},
   "source": [
    "And now we have an FSA describing the word \"cat\". Only one thing is missing, and that's to set a final state, that way the FSA knows that \"cat\" is a complete word on our language. We do this by simply calling `Fst.set_final()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.set_final(fourth_state)\n",
    "print_fst(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53081759",
   "metadata": {},
   "source": [
    "To prove that our FSA recognizes the word \"cat\" we can call `Fst.string()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c768b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab6c77",
   "metadata": {},
   "source": [
    "Now let's expand our FSA to also recognize \"cab\". To save space and typing let's do this in a for loop, keeping track of our place in the graph using `curr_state` and `next_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edffe6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_state = initial_state\n",
    "word = 'cab'\n",
    "for letter in word:\n",
    "    letter_code = ord(letter)\n",
    "    next_state = f.add_state()\n",
    "    arc_to_next_state = pynini.Arc(letter_code, letter_code, nullweight, next_state)\n",
    "    f.add_arc(curr_state, arc_to_next_state)\n",
    "    curr_state = next_state\n",
    "f.set_final(curr_state)\n",
    "print_fst(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9448eea",
   "metadata": {},
   "source": [
    "Our graph here is a bit redundant. If \"cat\" and \"cab\" both share the prefix \"ca\", why does the graph split at the beginning? Shouldn't the graph only split where the words diverge, namely at t/b?\n",
    "\n",
    "A lot of work has been done on optimizing and pruning FST graphs. While I won't go into any of that here, I do want to point out the function `pynini.optimize()` which will perform various functions to eliminate redundancies and improve performance on a given FST. Take a look at what our graph looks like pre- and post-optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d18faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_optimized = pynini.optimize(f)\n",
    "print_fst(f_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33320177",
   "metadata": {},
   "source": [
    "Also notice that we can have two arcs going between two states. Because of this, \"cat\" and \"car\" don't need to end up in different *states* at all, as long as the arc leading into the final state can be either an \"rb or a \"t\".\n",
    "\n",
    "Let's imagine a different scenario. Let's edit the unoptimized FSA `f` to add 'cabs' to the language, so that we accept 'cab', 'cabs' and 'cat', but not 'cats'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_state = f.add_state()\n",
    "plural_suffix = 's'\n",
    "plural_suffix_code = ord(plural_suffix)\n",
    "arc_to_cars = pynini.Arc(plural_suffix_code, plural_suffix_code, nullweight, cars_state)\n",
    "f.add_arc(curr_state, arc_to_cars)\n",
    "f.set_final(cars_state)\n",
    "print_fst(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97621a0b",
   "metadata": {},
   "source": [
    "**PAUSE:** What do you think this new graph will look like when optimized?  \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "(blank space to prevent the temptation to scroll down)\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each path does need a diverging state, else there would be no way to prevent adding an \"s\" after \"cat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_optimized = pynini.optimize(f)\n",
    "print_fst(f_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14ca4c",
   "metadata": {},
   "source": [
    "**EXERCISE 1:** Create an FSA accepting the language {\"student\", \"students\", \"teacher\", \"teachers\", \"person\", \"people\"}. You should make \"teachers/students\" ideally by first building a complete path for \"teacher/student\" and then adding an arc to a new state that adds the \"s\" suffix. Bonus points if you can make \"student\" and \"teacher\" end at the same point so that only one path for plural \"s\" is needed, rather than one for each word. Also remember that a valid path on an FSA must terminate in a final state!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixable_words = [\"student\", \"teacher\"]\n",
    "unsuffixable_words = [\"person\", \"people\"]\n",
    "\n",
    "f = pynini.Fst()\n",
    "f.set_input_symbols(ascii_table)\n",
    "f.set_output_symbols(ascii_table)\n",
    "initial_state = f.add_state()\n",
    "f.set_start(initial_state)\n",
    "\n",
    "curr_state = initial_state\n",
    "for word in suffixable_words:\n",
    "    for letter in word:\n",
    "        next_state = f.add_state()\n",
    "        # Your code here\n",
    "\n",
    "for word in unsuffixable_words:\n",
    "    for letter in word:\n",
    "        next_state = f.add_state()\n",
    "        # Your code here\n",
    "\n",
    "print_fst(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7575e8f",
   "metadata": {},
   "source": [
    "## Section 2: FSTs\n",
    "Now that we've covered FSAs (which are a special case of FST), let's cover FSTs more broadly.\n",
    "\n",
    "Note the difference in name between Finite State *Acceptor* and Finite State *Transducer*. Where an FSA merely *accepts* a language, an FST *transduces* between two languages.\n",
    "\n",
    "What does it mean to transduce between languages? Let's imagine two scenarios. In one, we transduce a set of singular nouns to their plural, and in another we transduce a set of words to their respective phonemes. We can represent these mathematically as mappings, i.e. {\"student\", \"students\", \"teacher\", \"teachers\", \"person\", \"people\"} or {\"cat\": \"k ae t\", \"cab\":  \"k ae b\"}. An FSA, then, can be thought of as vacuously \"transducing\" from one language to itself, i.e. {\"cat\": \"cat\", \"cab\": \"cab\"}.\n",
    "\n",
    "Let's see this in action mapping \"lock\" and \"box\" to their phonemes. We'll make use of the *epsilon* symbol, represented in the `SymbolTable` we defined above as `<eps>`. This represents an empty label, and will allow us to have an input word with a different length than the output word. Epsilon is always indexed to 0 for a given FST in Pynini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f20df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = '<eps>'\n",
    "epsilon_code = 0\n",
    "words_and_phonemes = [\n",
    "    (['l', 'o', 'c', 'k'],      ['l', 'a', 'k', epsilon]),\n",
    "    (['b', 'o', 'x', epsilon],  ['b', 'a', 'k', 's']),\n",
    "]\n",
    "\n",
    "word2phonemes = pynini.Fst()\n",
    "word2phonemes.set_input_symbols(ascii_table)\n",
    "word2phonemes.set_output_symbols(ascii_table)\n",
    "\n",
    "initial_state = word2phonemes.add_state()\n",
    "word2phonemes.set_start(initial_state)\n",
    "\n",
    "for word, phones in words_and_phonemes:\n",
    "    curr_state = initial_state\n",
    "    for input_letter, output_letter in zip(word, phones):\n",
    "        input_code = ord(input_letter) if input_letter!=epsilon else epsilon_code\n",
    "        output_code = ord(output_letter) if output_letter!=epsilon else epsilon_code\n",
    "\n",
    "        next_state = word2phonemes.add_state()\n",
    "        next_arc = pynini.Arc(input_code, output_code, nullweight, next_state)\n",
    "        word2phonemes.add_arc(curr_state, next_arc)\n",
    "        curr_state = next_state\n",
    "    word2phonemes.set_final(curr_state)\n",
    "print_fst(word2phonemes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682ab71",
   "metadata": {},
   "source": [
    "Now we have a graph mapping words to phonemes, but how do we use it? We can make use of a versatile tool called **FST composition**. While a formal definition of FST composition can be somewhat difficult to parse for those less familiar with set theory, the intuitive explanation is much easier to grasp.\n",
    "\n",
    "We've been talking about FSTs as a graph that models a language or a relation between two languages. In the latter case, we talk about an *input language* (words in the case above) and an *output language* (phonemes in the case above). This allows us to talk about the FST as a *function* that maps the input language to the output language.\n",
    "\n",
    "Any mathematical function can be reduced to a mapping of inputs to outputs. For example, the function $f(x)=x^2$ maps a number $x$ to its square. Likewise, the function $h(x)=2x$ maps a number $x$ to the number that is twice its value. The composition of these functions, e.g. $f(h(x))$ outputs the square of twice of $x$, since $f(x)$ is applied to the output of $h(x)$, and vice versa with $h(f(x))$, which outputs twice the square of $x$.\n",
    "\n",
    "We can represent the composition $f(h(x))$ as $h\\circ{f}(x)$ and vice versa---notice the flip in order, this is because for the notation $f(h(x))$ we do the computation inwards-out: $h$ then $x$. For the notation $h\\circ{f}$ we do the computation left-to-right, and so we still do the same order $h$ then $f$.\n",
    "Let's extend this to FSTs. If we have one FST $A$ that maps $a\\mapsto{b}$ and another FST $B$ that maps $b\\mapsto{c}$, then the composition $A\\circ{B}$ maps $a\\mapsto{c}$.\n",
    "\n",
    "Now for a simple example. Let's create an FSA for the word 'lock', and compose it with the graph we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2827da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_fsa = pynini.Fst()\n",
    "word_fsa.set_input_symbols(ascii_table)\n",
    "word_fsa.set_output_symbols(ascii_table)\n",
    "initial_state=word_fsa.add_state()\n",
    "word_fsa.set_start(initial_state)\n",
    "\n",
    "curr_state = initial_state\n",
    "word = 'lock'\n",
    "\n",
    "for letter in word:\n",
    "    next_state = word_fsa.add_state()\n",
    "    letter_code = ord(letter)\n",
    "    next_arc = pynini.Arc(letter_code, letter_code, nullweight, next_state)\n",
    "    word_fsa.add_arc(curr_state, next_arc)\n",
    "    curr_state = next_state\n",
    "word_fsa.set_final(curr_state)\n",
    "print_fst(word_fsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e68d4d",
   "metadata": {},
   "source": [
    "In Pynini FST composition can be done easily with the `@` symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_fst=word_fsa@word2phonemes\n",
    "print_fst(composed_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf0415",
   "metadata": {},
   "source": [
    "Now we can get the phonemes for the word \"lock\" by calling `Fst.string()` on the composed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_fsa.string(), composed_fst.string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c4d008",
   "metadata": {},
   "source": [
    "What if instead we have a list of phonemes and we want to transduce them to the matching word? We can simply invert the `word2phonemes` graph and then compose it with an FSA with our respective phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes2words = pynini.invert(word2phonemes)\n",
    "print_fst(phonemes2words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cbf010",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes_fsa = pynini.Fst()\n",
    "phonemes_fsa.set_input_symbols(ascii_table)\n",
    "phonemes_fsa.set_output_symbols(ascii_table)\n",
    "initial_state=phonemes_fsa.add_state()\n",
    "phonemes_fsa.set_start(initial_state)\n",
    "\n",
    "curr_state = initial_state\n",
    "phonemes = 'lak'\n",
    "\n",
    "for phoneme in phonemes:\n",
    "    next_state = phonemes_fsa.add_state()\n",
    "    letter_code = ord(phoneme)\n",
    "    next_arc = pynini.Arc(letter_code, letter_code, nullweight, next_state)\n",
    "    phonemes_fsa.add_arc(curr_state, next_arc)\n",
    "    curr_state = next_state\n",
    "phonemes_fsa.set_final(curr_state)\n",
    "print_fst(phonemes_fsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37075f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_fst = phonemes_fsa@phonemes2words\n",
    "print_fst(composed_fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b73a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes_fsa.string(), composed_fst.string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f915b78",
   "metadata": {},
   "source": [
    "While in this case it might seem like we got little juice out of a very effortful squeeze, the concept of FST composition will prove to be very versatile and useful for the remainder of this tutorial.\n",
    "\n",
    "**EXERCISE 2:** Write a generic function `add_path` that adds a path to an FST mapping any input string to any output string. Recall from above that when we matched \"lock\" to [lak] and \"box\" to [baks] we manually padded the shorter sequence with an epsilon. In your function, you will need to handle epsilon insertion dynamically, as you don't know ahead of time which sequence is longer and by how much. The function should return `curr_state`, which will point to the last state in the path added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path(f: pynini.Fst, curr_state: int, input_str: str, output_str: str):\n",
    "    # pad input_str or output_str here\n",
    "\n",
    "    for input_letter, output_letter in zip(input_str, output_str):\n",
    "        ...\n",
    "        # add arcs for path here\n",
    "\n",
    "    return curr_state\n",
    "    \n",
    "\n",
    "f = pynini.Fst()\n",
    "f.set_input_symbols(ascii_table)\n",
    "f.set_output_symbols(ascii_table)\n",
    "initial_state = f.add_state()\n",
    "f.set_start(initial_state)\n",
    "\n",
    "\n",
    "input_str = \"elocution\"\n",
    "output_str = \"ehlowkyushaxn\" # linguists may find Arpabet strings unseemly. I can sympathize.\n",
    "\n",
    "last_state = add_path(f, curr_state=initial_state, input_str=input_str, output_str=output_str)\n",
    "print_fst(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52317fc3",
   "metadata": {},
   "source": [
    "**Exercise 3:** Using the `add_path` function you just wrote, create one FST that maps singular nouns to plural and another that maps words to phonemes. Then compose the two so that you have a graph mapping words to the phonemes of the plural form of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb12ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_and_phonemes = [\n",
    "    (\"student\", \"stuwdixnt\"),\n",
    "    (\"students\", \"stuwdixnts\"),\n",
    "    (\"teacher\", \"tiychaxr\"),\n",
    "    (\"teachers\", \"tiychaxrz\"),\n",
    "    (\"person\", \"paxrsahn\"),\n",
    "    (\"people\", \"piypaxl\"),\n",
    "]\n",
    "\n",
    "word2phonemes = pynini.Fst()\n",
    "word2phonemes.set_input_symbols(ascii_table)\n",
    "word2phonemes.set_output_symbols(ascii_table)\n",
    "initial_state =  word2phonemes.add_state()\n",
    "word2phonemes.set_start(initial_state)\n",
    "\n",
    "# build an FST mapping all words from the list above to their respective phonemes\n",
    "\n",
    "print_fst(word2phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ddcedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "singulars_and_plurals = [\n",
    "    (\"student\", \"students\"),\n",
    "    (\"teacher\", \"teachers\"),\n",
    "    (\"person\", \"people\"),\n",
    "]\n",
    "\n",
    "singular2plural = pynini.Fst()\n",
    "singular2plural.set_input_symbols(ascii_table)\n",
    "singular2plural.set_output_symbols(ascii_table)\n",
    "initial_state =  singular2plural.add_state()\n",
    "singular2plural.set_start(initial_state)\n",
    "\n",
    "# build an FST mapping all words from the list above to their respective plural forms\n",
    "# your code here\n",
    "\n",
    "print_fst(singular2plural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, compose the previous to graphs so that it maps a word to the phonemes of its plural\n",
    "composed_fst = pynini.Fst() # delete and replace with your code\n",
    "print_fst(composed_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5e0ec",
   "metadata": {},
   "source": [
    "**EXERCISE 4:** Using `word2phonemes` and `singular2plural` from Exercise 3, create an FST that maps a sequence of *phonemes* to the *plural form* of the corresponding word. One of the graphs will need to be inverted. Also think about what order the FSTs should be composed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7afd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_fst = pynini.invert(pynini.Fst()) # delete and replace with your own code\n",
    "composed_fst = pynini.Fst()\n",
    "print_fst(composed_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53390197",
   "metadata": {},
   "source": [
    "## Section 3: Weighted FSTs\n",
    "Up until now we've been ignoring the `weight` parameter when building FSTs. Now let's explain what this weight does.\n",
    "\n",
    "A *weight* on an arc can be thought of as some cost associated with it. If we think of graphs as a type of map, where arcs are roads and states are geographic destinations, then an arc's weight can be thought of as the spacial distance of a road connecting two destinations. Generally, if you're trying to get from point $A$ to point $B$, you're probably going to want to take the shortest route possible. That means that you'll try to minimize the total distance of the roads you travel, or in FST-land, you'll try to minimize the weight of the arcs you traverse. From now on, I'll use Weighted Finite State Transducer (WFST) to refer to an FST with weights/costs and FST as an umbrella term for FSTs with and without weight/cost.\n",
    "\n",
    "Terminology note: though Pynini (and most of the FST literature) uses the term `weight` in its API, I will prefer the term 'cost' where possible to avoid confusion with a weight in a neural network, since a neural network larger weight indicates *higher* probability of a given connection, whereas a larger WFST weight/cost indicates *lower* probability. The term 'WFST' itself is pretty standardly entrenched, though, so I won't use a term like \"Cost Finite State Transducer.\"\n",
    "\n",
    "In terms of modeling language, we can think of cost as the inverse probability or frequency of a given mapping. Take the English verb 'dive' for example, for which 'dived' and 'dove' are considered proper forms of the past tense. Let's assume for the sake of this exercise that 'dived' is used more often than 'dove', which we can represent by giving 'dived' a smaller cost. Notice that the cost is indicate on the graph following a forward slash after the input:output symbols. In this graph, the cost is only specified at the junction where \"dived\" and \"dove\" diverge, as only one difference in cost is needed in order for either path to be more or less costly overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dive_past_tense = pynini.Fst()\n",
    "dive_past_tense.set_input_symbols(ascii_table)\n",
    "dive_past_tense.set_output_symbols(ascii_table)\n",
    "initial_state = dive_past_tense.add_state()\n",
    "dive_past_tense.set_start(initial_state)\n",
    "\n",
    "\n",
    "present_form = \"dive\"\n",
    "dove_cost = 1\n",
    "dived_cost = 2\n",
    "past_forms = [(\"dove\", dove_cost), (\"dived\", dived_cost)]\n",
    "\n",
    "# first create path accepting \"dive\" as input\n",
    "curr_state = initial_state\n",
    "for letter in present_form:\n",
    "    letter_code = ord(letter)\n",
    "    next_state = dive_past_tense.add_state()\n",
    "    next_arc = pynini.Arc(letter_code, epsilon_code, nullweight, next_state)\n",
    "    dive_past_tense.add_arc(curr_state, next_arc)\n",
    "    curr_state = next_state\n",
    "\n",
    "\n",
    "# now continue the path with either \"dived\" or \"dove\" as output\n",
    "# with the appropriate cost for each form\n",
    "present_form_end_state = curr_state\n",
    "for past_form, cost in past_forms:\n",
    "    curr_state = dive_past_tense.add_state()\n",
    "    arc_to_past_form = pynini.Arc(epsilon_code, epsilon_code, cost, curr_state)\n",
    "    dive_past_tense.add_arc(present_form_end_state, arc_to_past_form)\n",
    "\n",
    "    for letter in past_form:\n",
    "        next_state = dive_past_tense.add_state()\n",
    "        letter_code = ord(letter)\n",
    "        next_arc = pynini.Arc(epsilon_code, letter_code, nullweight, next_state)\n",
    "        dive_past_tense.add_arc(curr_state, next_arc)\n",
    "        curr_state = next_state\n",
    "    dive_past_tense.set_final(curr_state)\n",
    "\n",
    "print_fst(dive_past_tense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a009751c",
   "metadata": {},
   "source": [
    "We can then use the `pynini.shortestpath()` function to find the most likely form on the given graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae471de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dive_shortestpath = pynini.shortestpath(dive_past_tense)\n",
    "print(dive_shortestpath.string())\n",
    "print_fst(dive_shortestpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bceb19",
   "metadata": {},
   "source": [
    "**EXERCISE 5:** Create a WFST mapping \"the\" to ARPABET [dhiy] (IPA [ði]) with a cost of 2 and [dhax] (IPA [ðə]) with a cost of 1. Then print the shortest path. Which pronunciation is more probable given this graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60983c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "orthography = \"the\"\n",
    "pronunciations_and_costs = [(\"dhiy\", 2), (\"dhax\", 1)]\n",
    "\n",
    "the_pronunciation = pynini.Fst()\n",
    "the_pronunciation.set_input_symbols(ascii_table)\n",
    "the_pronunciation.set_output_symbols(ascii_table)\n",
    "\n",
    "initial_state = the_pronunciation.add_state()\n",
    "the_pronunciation.set_start(initial_state)\n",
    "\n",
    "# your code here\n",
    "\n",
    "print_fst(the_pronunciation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_shortestpath = pynini.shortestpath(the_pronunciation)\n",
    "# print(the_shortestpath.string()) # commented to prevent an error: uncomment when you've completed the part above\n",
    "print_fst(the_shortestpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69ca23",
   "metadata": {},
   "source": [
    "## Section 4: Efficient FST creation with Pynini\n",
    "So far writing FSTs has been a bit tedious, since we need to add each state and arc separately. Now that we've wrapped our head around the inner workings of FSTs, though, we can cheat a bit and use pre-built methods in Pynini that will make our lives much easier.\n",
    "\n",
    "For example, we can create a simple FSA using `pynini.accep` and a transducer with `pynini.cross`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd402ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_fsa = pynini.accep(\"cat\")\n",
    "\n",
    "cat_fsa.set_input_symbols(ascii_table)\n",
    "cat_fsa.set_output_symbols(ascii_table)\n",
    "\n",
    "print_fst(cat_fsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7c61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2dog_fst = pynini.cross(\"cat\", \"dog\")\n",
    "\n",
    "cat2dog_fst.set_input_symbols(ascii_table)\n",
    "cat2dog_fst.set_output_symbols(ascii_table)\n",
    "\n",
    "print_fst(cat2dog_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7457e2",
   "metadata": {},
   "source": [
    "We can do other operations like concatenate or take a union of several FSTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6372903",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_fst(cat_fsa+cat_fsa+cat2dog_fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_fsa = pynini.accep(\"dog\")\n",
    "dog_fsa.set_input_symbols(ascii_table)\n",
    "dog_fsa.set_output_symbols(ascii_table)\n",
    "\n",
    "cat_or_dog_fsa = cat_fsa|dog_fsa\n",
    "print_fst(cat_or_dog_fsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a06db",
   "metadata": {},
   "source": [
    "We can also take a \"closure\" over an FST, which is like the star operator in regular expressions: it produces an FST corresponding to zero or arbitrarily many of the original FST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11579f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2dog_closure = pynini.closure(cat2dog_fst).optimize()\n",
    "print_fst(cat2dog_closure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc9212",
   "metadata": {},
   "source": [
    "Since closure allows for zero repetitions, `(\"\"@cat2dog_closure).string()` will return an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681280d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"catcatcatcat\"@cat2dog_closure).string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df83d5",
   "metadata": {},
   "source": [
    "Similar to `pynini.closure()` we can use `Fst.plus` to allow 1 or more (but not zero) repetitions of the FST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4baf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2dog_plus = cat2dog_fst.plus.optimize()\n",
    "print_fst(cat2dog_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854dbd68",
   "metadata": {},
   "source": [
    "Since plus allows for one or more repetitions, `(\"\"@cat2dog_plus).string()` will raise an FST compilation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"catcatcat\"@cat2dog_plus).string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecacb9c",
   "metadata": {},
   "source": [
    "We can even transduce between two FSTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_fsa = pynini.accep(\"fish\")\n",
    "fish_fsa.set_input_symbols(ascii_table)\n",
    "fish_fsa.set_output_symbols(ascii_table)\n",
    "\n",
    "cat_or_dog2fish_fst = pynini.cross(cat_or_dog_fsa, fish_fsa)\n",
    "print_fst(cat_or_dog2fish_fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish2cat_or_dog_fst = pynini.cross(fish_fsa, cat_or_dog_fsa)\n",
    "print_fst(fish2cat_or_dog_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1153a",
   "metadata": {},
   "source": [
    "Remember the FSTs we made for Exercise 3? Each can be made in a single line (not counting the boilerplate for setting symbol tables and optimizing) using `pynini.string_map()`, which takes a list of tuples as input and returns an FST mapping the first element of each tuple to the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2phonemes = pynini.string_map(words_and_phonemes)\n",
    "word2phonemes.set_input_symbols(ascii_table)\n",
    "word2phonemes.set_output_symbols(ascii_table)\n",
    "word2phonemes.optimize()\n",
    "print_fst(word2phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625929ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "singular2plural = pynini.string_map(singulars_and_plurals)\n",
    "singular2plural.set_input_symbols(ascii_table)\n",
    "singular2plural.set_output_symbols(ascii_table)\n",
    "singular2plural.optimize()\n",
    "print_fst(singular2plural)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0c2bb",
   "metadata": {},
   "source": [
    "Pynini also autocasts a string to an FSA over the same string, which can make FST composition much more concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"student\"@singular2plural).string(), (\"student\"@word2phonemes).string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd78d8",
   "metadata": {},
   "source": [
    "Just like we added costs to arcs before, now we can add a cost for an entire FST. Let's repeat the dive/dived/dove example from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dive_fsa = pynini.accep(\"dive\")\n",
    "dove_fsa = pynini.accep(\"dove\", weight=dove_cost)\n",
    "dived_fsa = pynini.accep(\"dived\", weight=dived_cost)\n",
    "\n",
    "past_forms_fsa = pynini.union(dove_fsa, dived_fsa)\n",
    "dive_past_tense = pynini.cross(dive_fsa, past_forms_fsa)\n",
    "dive_past_tense.set_input_symbols(ascii_table)\n",
    "dive_past_tense.set_output_symbols(ascii_table)\n",
    "\n",
    "print_fst(dive_past_tense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc470117",
   "metadata": {},
   "outputs": [],
   "source": [
    "dive_shortestpath = pynini.shortestpath(dive_past_tense)\n",
    "print(dive_shortestpath.string())\n",
    "print_fst(dive_shortestpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b5173a",
   "metadata": {},
   "source": [
    "**EXERCISE 6:** Repeat Exercise 5, this time using convenient Pynini functions rather than building the entire WFST from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_pronunciation = pynini.cross('', '')\n",
    "the_pronunciation.set_input_symbols(ascii_table)\n",
    "the_pronunciation.set_output_symbols(ascii_table)\n",
    "\n",
    "print_fst(the_pronunciation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d523da",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_shortestpath = pynini.shortestpath(the_pronunciation)\n",
    "print(the_shortestpath.string())\n",
    "print_fst(the_shortestpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267403b4",
   "metadata": {},
   "source": [
    "Now let's expand our example. We first need to define a dictionary that stores words and their associated phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a28523",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {\n",
    "    \"she\": \"sh iy\",\n",
    "    \"sells\": \"s eh l z\",\n",
    "    \"seashells\": \"s iy sh eh l z\",\n",
    "    \"by\": \"b ay\",\n",
    "    \"the\": \"dh ax\",\n",
    "    \"seashore\": \"s iy sh aw r\",\n",
    "}\n",
    "\n",
    "words = set()\n",
    "phones = set()\n",
    "\n",
    "for word, phone_list in lexicon.items():\n",
    "    words.add(word)\n",
    "    phones.update(phone_list.split())\n",
    "words, phones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a3e96",
   "metadata": {},
   "source": [
    "Whereas before we were using one arc per letter and used the `ascii_table` for rendering, this time we'll define a specific `SymbolTable` where each word and phone in our lexicon has a unique symbol, which will greatly help readability when rendering FSTs.\n",
    "\n",
    "To avoid having to constantly set the symbol table each time we create an FST, we write the `fsa` function which returns an FSA with the symbol table already set. We can then use this as input to any other Pynini FST function and the symbol table will persist. We likewise define the `fst_string()` function since `Fst.string()` requires passing the symbol table even if it has already been set for the FST object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = pynini.SymbolTable()\n",
    "symbols.add_symbol('<eps>')\n",
    "\n",
    "for word in words:\n",
    "    symbols.add_symbol(word)\n",
    "\n",
    "for phone in phones:\n",
    "    symbols.add_symbol(phone)\n",
    "\n",
    "def set_symbols(f: pynini.Fst) -> pynini.Fst:\n",
    "    \"\"\"\n",
    "    Set input and output symbols for a FST `f` to the\n",
    "    user-defined symbol table.\n",
    "    \"\"\"\n",
    "    f=f.set_input_symbols(symbols)\n",
    "    f=f.set_output_symbols(symbols)\n",
    "    return f\n",
    "\n",
    "def fsa(acceptor_str: Union[str, List[str]], weight: Optional[pynini.WeightLike]=None) -> pynini.Fst:\n",
    "    \"\"\"\n",
    "    Create a Finite State Acceptor of the given string using\n",
    "    the symbols table.\n",
    "    \"\"\"\n",
    "    if type(acceptor_str) is list:\n",
    "        acceptor_str = ' '.join(acceptor_str)\n",
    "    f=pynini.accep(acceptor_str, weight=weight, token_type=symbols)\n",
    "    f=set_symbols(f)\n",
    "    f=f.optimize()\n",
    "    return f\n",
    "\n",
    "def fst_string(f):\n",
    "    return f.string(token_type=symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f0f8dd",
   "metadata": {},
   "source": [
    "Let's create an FST mapping words to phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2phonemes=pynini.string_map(lexicon.items(), input_token_type=symbols, output_token_type=symbols)\n",
    "set_symbols(word2phonemes)\n",
    "print_fst(word2phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193ef8e",
   "metadata": {},
   "source": [
    "Notice how the FST changes shape and loses the vacuous `<eps>:<eps>` arcs when we optimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147415d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_fst(word2phonemes.optimize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f583c89",
   "metadata": {},
   "source": [
    "Now let's make an inverted FST mapping words to phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes2word = pynini.invert(word2phonemes)\n",
    "print_fst(phonemes2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2728ce3a",
   "metadata": {},
   "source": [
    "We can compose an FST of a phoneme sequence with `phonemes2word` to get the corresponding word. Note that we need to use the `fsa` method we defined earlier since if we let Pynini autocast a string it won't set the symbol table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=fsa(\"sh iy\")@phonemes2word\n",
    "print(fst_string(f))\n",
    "print_fst(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488bf6f",
   "metadata": {},
   "source": [
    "(Just to show that if we don't wrap the string with the `fsa` function we don't get any output due to the symbol table mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a759ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_fst(\"sh iy\"@phonemes2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc108947",
   "metadata": {},
   "source": [
    "Or vice versa to get a list of phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a667b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=fsa(\"seashells\")@word2phonemes\n",
    "print(fst_string(f))\n",
    "print_fst(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4a008d",
   "metadata": {},
   "source": [
    "## Section 5: Applying FSTs to speech\n",
    "Now let's think about how this will be applied in the ASR case. For ASR, we won't be mapping a simple sequence of phonemes to words. Instead, our input is *variable in length* and it is a *probability distribution over phonemes*.\n",
    "\n",
    "Let's tackle the first part, variability in length. In speech, we don't know ahead of time how long each phoneme will be (and in many cases, it may be difficult or even impossible to clearly delimit the boundaries of one phoneme from the next). Let's make one simplifying assumption: if we define a certain minimum time span, e.g. 10ms, we can expect that any given phoneme will correspond to one or more consecutive units of that time span. So if a phoneme /a/ lasts for 97ms, we will model it as a sequence of nine 10ms intervals.\n",
    "\n",
    "What does this mean for our FSTs? Now if we have an FST converting a pronunciation to the respective word, it needs to be able to handle *repeating instances of each phoneme*. For example [sh iy], [sh sh iy iy] and [sh sh sh iy iy iy iy iy] all need to map to \"she\". We can do this by using the `Fst.plus` operator provided by Pynini we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "she_pronunciation_fsa = fsa(\"sh\").plus + fsa(\"iy\").plus\n",
    "she_pronunciation_fsa.optimize()\n",
    "print_fst(she_pronunciation_fsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "she_pronunciation_fst = pynini.cross(she_pronunciation_fsa, fsa(\"she\"))\n",
    "print_fst(she_pronunciation_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d54e76",
   "metadata": {},
   "source": [
    "Try running the following cell while varying the number of [sh]'s and [iy]'s, you should always get the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47381e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_she_pronunciation = fsa(\"sh sh sh sh iy iy iy\")@she_pronunciation_fst\n",
    "print(fst_string(composed_she_pronunciation))\n",
    "print_fst(composed_she_pronunciation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4f6f4",
   "metadata": {},
   "source": [
    "Let's encapsulate the logic for making an FSA allowing for multiple repetitions of each phoneme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phoneme_fsa(phoneme_str):\n",
    "    phoneme_fsa = fsa(\"\")\n",
    "    for phoneme in phoneme_str.split():\n",
    "        phoneme_fsa += fsa(phoneme).plus\n",
    "    phoneme_fsa.optimize()\n",
    "    return phoneme_fsa\n",
    "seashells_fsa = phoneme_fsa(\"s iy sh eh l z\")\n",
    "print_fst(seashells_fsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb8652",
   "metadata": {},
   "source": [
    "Let's now recreate our FST mapping phonemes to words using this logic. We can do this by making several FSTs with `pynini.cross()` that each map one phoneme sequence to a particular word, and then take the union over these FSTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c396977",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone2word_fsts = [\n",
    "    pynini.cross(phoneme_fsa(value), fsa(key))\n",
    "    for key, value in lexicon.items()\n",
    "]\n",
    "\n",
    "phonemes_plus2words = pynini.union(*phone2word_fsts)\n",
    "phonemes_plus2words.optimize()\n",
    "phonemes_plus2words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f0ba9f",
   "metadata": {},
   "source": [
    "Try changing the phonemes in the following cell to output different words on our lexicon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22bde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_pronunciation = fsa(\"s s iy iy iy sh eh eh l z z\")@phonemes_plus2words\n",
    "print(fst_string(composed_pronunciation))\n",
    "print_fst(composed_pronunciation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41509a85",
   "metadata": {},
   "source": [
    "Our FST `phonemes_plus2words` allows us to map a pronunciation to a *single word* on our lexicon. What if we want to map a sequence of words? We can do this simply by taking a closure over `phoneme_plus2words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90180f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes2words_closure = pynini.closure(phonemes_plus2words)\n",
    "print_fst(phonemes2words_closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_pronunciation_sequence = fsa(\"sh sh iy iy s s eh l l z s iy iy sh sh eh l l z\")@phonemes2words_closure\n",
    "print(fst_string(composed_pronunciation_sequence))\n",
    "print_fst(composed_pronunciation_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e2f5d5",
   "metadata": {},
   "source": [
    "**EXERCISE 7:** Create an FST that models the pronunciation for any number of repetitions of \"she sells\" and rejects any other words. So it should map:\n",
    "- sh iy s eh l z > \"she sells\"\n",
    "- sh sh iy iy s s eh l l z z > \"she sells\"\n",
    "- sh iy iy s eh l z sh iy iy s s eh l z > \"she sells she sells\"  \n",
    "\n",
    "And so on. But it should *not* accept:\n",
    "- sh iy sh iy s eh l l z > *she she sells\n",
    "\n",
    "\n",
    "Hint: first make an FST accepting a single instance of \"she sells\" then make a closure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded39365",
   "metadata": {},
   "outputs": [],
   "source": [
    "shesells_fst = pynini.cross(fsa(''), fsa(''))\n",
    "shesells_closure_fst = pynini.closure(fsa(''))\n",
    "\n",
    "shesells_closure_fst.optimize()\n",
    "print_fst(shesells_closure_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2212572b",
   "metadata": {},
   "source": [
    "Now let's address the second part of using FSTs with speech mentioned above, namely that we will input *probability distributions of phonemes* rather than discrete phonemes. Let's demonstrate this by creating an FST that can map the phonemes for [dh dh ax ax] or [sh sh iy iy], but has higher probability for [sh sh iy iy]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_probabilities = (fsa(\"sh\", weight=1.0) | fsa(\"dh\", weight=1.0)) +\\\n",
    "    (fsa(\"sh\", weight=0.5) | fsa(\"dh\", weight=0.9)) +\\\n",
    "    (fsa(\"sh\", weight=0.2) | fsa(\"dh\", weight=0.7)) +\\\n",
    "    (fsa(\"iy\", weight=0.5) | fsa(\"ax\", weight=0.9)) +\\\n",
    "    (fsa(\"iy\", weight=0.5) | fsa(\"ax\", weight=0.4)) +\\\n",
    "    (fsa(\"iy\", weight=0.9) | fsa(\"ax\", weight=1.0))\n",
    "phoneme_probabilities.optimize()\n",
    "print_fst(phoneme_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7572f10",
   "metadata": {},
   "source": [
    "When we compose this with our FST mapping phonemes to words, we get a probability distribution over the words \"the\" and \"she.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b059661",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonem_probs_composed = phoneme_probabilities@phonemes2words_closure\n",
    "phonem_probs_composed.optimize()\n",
    "print_fst(phonem_probs_composed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b930243",
   "metadata": {},
   "source": [
    "Let's then take the shortest path to see that \"she\" is the most likely word for these phoneme probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_probs_shortestpath = pynini.shortestpath(phonem_probs_composed)\n",
    "print(fst_string(phoneme_probs_shortestpath))\n",
    "print_fst(phoneme_probs_shortestpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617a5e0",
   "metadata": {},
   "source": [
    "Let's make our lives a bit easier and encapsulate the logic for making a phoneme probability FST. We'll do this by first making a matrix where each row is a timestep and each column is a phoneme (with the column indices determined by the `phonelist` defined below), and then build an FST based on the costs defined in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cf414",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonelist = list(phones)\n",
    "phonelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ba08f",
   "metadata": {},
   "source": [
    "I've left some code here that will make \"seashore\" be the most likely word output and \"by the seashore\" the second most likely. I've also left commented-out code that will let you set random costs, feel free to play around and see what words you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ab4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 20\n",
    "\n",
    "# UNCOMMENT THIS LINE TO USE RANDOM PROBABILITIES\n",
    "# cost_matrix = np.random.random((num_timesteps, len(phonelist)))\n",
    "\n",
    "# UNCOMMENT THIS BLOCK TO SET \"seashore\" as most probable and \"by the seashore\" as second mostp probable\n",
    "cost_matrix = np.ones((num_timesteps, len(phonelist)))\n",
    "\n",
    "cost_matrix[1:11, phonelist.index(\"s\" )] = 0.5\n",
    "cost_matrix[11:13, phonelist.index(\"iy\")] = 0.5\n",
    "cost_matrix[13:15, phonelist.index(\"sh\")] = 0.4\n",
    "cost_matrix[15:17, phonelist.index(\"aw\")] = 0.4\n",
    "cost_matrix[17:19, phonelist.index(\"r\")] = 0.4\n",
    "\n",
    "\n",
    "cost_matrix[1:5, phonelist.index(\"b\" )] = 0.6\n",
    "cost_matrix[5:7, phonelist.index(\"ay\")] = 0.5\n",
    "cost_matrix[7:9, phonelist.index(\"dh\")] = 0.4\n",
    "cost_matrix[9:10, phonelist.index(\"ax\")] = 0.4\n",
    "# END BLOCK\n",
    "\n",
    "def make_phone_probabilities(cost_matrix: np.ndarray) -> pynini.Fst:\n",
    "    phoneme_probs = fsa('')\n",
    "    for timestep_vector in cost_matrix:\n",
    "        timestep_probs = None\n",
    "        for i, phoneme in enumerate(phonelist):\n",
    "            phoneme_cost = timestep_vector[i]\n",
    "            phoneme_prob_fsa = fsa(phoneme, weight=phoneme_cost)\n",
    "            if timestep_probs is None:\n",
    "                timestep_probs = phoneme_prob_fsa\n",
    "            else:\n",
    "                timestep_probs = timestep_probs | phoneme_prob_fsa\n",
    "        phoneme_probs = phoneme_probs + timestep_probs\n",
    "    return phoneme_probs.optimize()\n",
    "phoneme_probs = make_phone_probabilities(cost_matrix)\n",
    "print_fst(phoneme_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa828b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_probs_composed = (phoneme_probs@phonemes2words_closure).optimize()\n",
    "probs_shortestpath = pynini.shortestpath(phoneme_probs_composed)\n",
    "print(fst_string(probs_shortestpath))\n",
    "print_fst(probs_shortestpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba2d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynini.lib.rewrite import lattice_to_nshortest, lattice_to_strings\n",
    "nshortest = lattice_to_nshortest(phoneme_probs_composed.project('output'), nshortest=2)\n",
    "lattice_to_strings(nshortest, token_type=symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15aa990",
   "metadata": {},
   "source": [
    "**EXERCISE 8:** Write a phoneme cost matrix that gives the phrase \"she sells seashells by the seashore\" the highest probability when composed with `phonemes2words_closure`. Copy and paste is your friend here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 50\n",
    "tonguetwister_matrix = np.ones((num_timesteps, len(phonelist)))\n",
    "tonguetwister_matrix[0:2, phonelist.index('sh')] = 0.5\n",
    "# your code here\n",
    "\n",
    "tonguetwister_probs = make_phone_probabilities(tonguetwister_matrix)\n",
    "tonguetwister_composed = (tonguetwister_probs@phonemes2words_closure).optimize()\n",
    "tonguetwister_shortestpath = pynini.shortestpath(tonguetwister_composed)\n",
    "print(fst_string(tonguetwister_shortestpath))\n",
    "print_fst(tonguetwister_shortestpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c3a60",
   "metadata": {},
   "source": [
    "# Section 6: Doing Keyword Search with WFSTs\n",
    "Now that we've discussed basic string mapping with WFSTs and even simulated a bit of ASR with WFSTs, it's time to get down to business and finally talk a bit about keyword search.\n",
    "\n",
    "For now, we'll focus on one particular architecture for keyword search consisting of a *keyword model* and a *background model*.\n",
    "\n",
    "What do I mean by \"model?\" Model here refers to a WFST or a particular path on the WFST. We can say that the lexicon WFST we built earlier is a *model* for the entire lexicon, and that the path that transduces \"sh sh... iy iy iy...\" to \"she\" as a *model* for the word \"she.\"\n",
    "\n",
    "In the context of KWS, we need two models. One that spots the keyword, and one that catches anything else. Let's say our keyword is \"sells.\" To model our keyword, we create a WFST mapping the phonemes /s eh l z/ to the word \"sells.\" As for why we're setting the weight to 0.9, we'll get to that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44888c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sells_model = phoneme_fsa(\"s eh l z\")\n",
    "sells_model = pynini.cross(sells_model, fsa(\"sells\", weight=0.9))\n",
    "sells_model.closure().optimize()\n",
    "print_fst(sells_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496d290",
   "metadata": {},
   "source": [
    "Now let's construct a background model. Whereas the keyword model \"spots\" a given keyword by transducing its constituent phones to the output word, the background model filters out all non-keyword speech by mapping all to a blank.\n",
    "\n",
    "Note we do this by first creating an FSA called \"sigmastar\" and then transducing it to blank. The name \"sigmastar\" (i.e. $\\Sigma\\ast$) comes from the convention of using the symbol $\\Sigma$ to represent the alphabet of a WFST, such that $\\Sigma\\ast$, using the Kleene star $\\ast$ as used in regular expressions, is any combination of zero or more letters from the alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6505cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmastar = pynini.union(*[fsa(phone, weight=1) for phone in phones]).closure().optimize()\n",
    "background_model = pynini.cross(sigmastar, fsa('')).optimize()\n",
    "print_fst(background_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afd5130",
   "metadata": {},
   "source": [
    "Now let's join the keyword model and background model into a single WFST. Note that we gave the keyword model a lower cost than the background model. Since the background model accepts *any* speech, the keyword model needs to have a lower cost in order for an instance of a keyword to prefer the keyword model. Otherwise, if we phoneme probabilities for the keyword, it might be captured by the background model and transduced to blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f902255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_fst = (background_model|sells_model).optimize()\n",
    "print_fst(kws_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ac408",
   "metadata": {},
   "source": [
    "Let's try composing our keyword search WFST with the phone probabilities we made for Exercise 8 and see if our model correctly identifies the keyword \"sells\" and ignores all other speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbfdedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_composed = (tonguetwister_probs@kws_fst).optimize()\n",
    "kws_shortestpath = pynini.shortestpath(kws_composed)\n",
    "print(fst_string(kws_shortestpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00fb3d9",
   "metadata": {},
   "source": [
    "How did yours do? When I ran it I got \"sells sells sells\" as the output. This means that the KWS model is not working perfectly: we got one **true positive** and two **false alarms** (i.e. false positive: \"false alarm\" is a term specifically used in *detection* tasks like KWS). This means we got a recall of 100% (1/1) but a precision of 33% (1/3), not too great!\n",
    "\n",
    "Let's consider a different kind of background model. This time, instead of naively mapping any sequence of phones to blank, we specifically map all items on the lexicon to blank *except* for our keyword \"sells,\" which we map to its proper output. This is a smarter approach since it uses our knowledge of the language to build the background model. Notice, however, the increased complexity: before our background model was just a mapping of all arbitrary sequences to blank. The only phoneme-to-word mapping we needed was for our keyword. Now, however, we need to specify phoneme-to-word mappings for *non*-keyword terms, even though the keyword is all we really care about! In essence, what we're doing here is doing **full-blown ASR** first and then throwing out anything that isn't a keyword.\n",
    "\n",
    "In practice, however, we don't need to go to the extreme of using a full-blown ASR system for the background model. We could instead model some small subset of common words. For example, [Rose and Paul 1990](http://ieeexplore.ieee.org/document/115555/) train a background model on the 80 most common words in English, and this does fairly well as a background model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_kws = [\n",
    "    pynini.cross(phoneme_fsa(value), fsa('sells' if key == 'sells' else ''))\n",
    "    for key, value in lexicon.items()\n",
    "]\n",
    "\n",
    "lexical_kws = pynini.union(*lexical_kws)\n",
    "lexical_kws.closure().optimize()\n",
    "print_fst(lexical_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca91192",
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_composed = (tonguetwister_probs@lexical_kws).optimize()\n",
    "kws_shortestpath = pynini.shortestpath(kws_composed)\n",
    "fst_string(kws_shortestpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c510f7",
   "metadata": {},
   "source": [
    "**EXERCISE 9:** Spotting only one keyword is pretty limiting, right? Construct WFSTS representing KWS model the spots \"sells\" and \"seashore\" and ignores all other words. Use both strategies discussed above for the background model and compare their performance against the phone probabilities from previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_model = phoneme_fsa('')\n",
    "background_model_naive = fsa('')\n",
    "\n",
    "kws_model_naive = keyword_model|background_model_naive\n",
    "kws_composed = (tonguetwister_probs@kws_model_naive).optimize()\n",
    "kws_shortestpath = pynini.shortestpath(kws_composed)\n",
    "fst_string(kws_shortestpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ead2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_model_smart = pynini.cross(phoneme_fsa(''), fsa(''))\n",
    "kws_composed = (tonguetwister_probs@kws_model_smart).optimize()\n",
    "kws_shortestpath = pynini.shortestpath(kws_composed)\n",
    "fst_string(kws_shortestpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
